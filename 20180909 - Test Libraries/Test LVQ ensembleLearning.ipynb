{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble learning với thuật toán LVQ cơ bản sử dụng tỉ lệ mẫu trong từng neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import euclidean_distances\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../SOM-LVQ')\n",
    "import LVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thend\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"../data/AReM/Dataset1(combined).csv\")\n",
    "x = data.iloc[:, 0:6].values\n",
    "y = data.iloc[:, 6].values\n",
    "y[y==7] = 0\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# use Minmaxscaler because we use euclidean distance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "x_train = minmax.fit_transform(x_train)\n",
    "x_test = minmax.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvq1 = LVQ.LVQ(x=x_train, y=y_train, n_classes=7, n_neurons=90, epsilon=0.9, p_vectors=[], epsilon_dec_factor=0.001)\n",
    "\n",
    "neurons = lvq1.train_LVQ2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.62      0.62       119\n",
      "          1       0.99      1.00      1.00       124\n",
      "          2       0.98      0.98      0.98       129\n",
      "          3       0.66      0.62      0.64       130\n",
      "          4       0.98      0.99      0.99       124\n",
      "          5       0.82      0.85      0.83       107\n",
      "          6       0.89      0.90      0.89       107\n",
      "\n",
      "avg / total       0.85      0.85      0.85       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_y = [lvq1.predict(instance) for instance in x_test]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(y_test, predicted_y, target_names=['0', '1', '2', '3', '4', '5', '6']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvq2 = LVQ.LVQ(x=x_train, y=y_train, n_classes=7, n_neurons=90, epsilon=0.9, p_vectors=[], epsilon_dec_factor=0.001)\n",
    "\n",
    "neurons = lvq2.train_LVQ2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71       119\n",
      "          1       0.99      1.00      1.00       124\n",
      "          2       0.98      0.98      0.98       129\n",
      "          3       0.73      0.72      0.72       130\n",
      "          4       0.98      1.00      0.99       124\n",
      "          5       0.81      0.78      0.79       107\n",
      "          6       0.84      0.87      0.85       107\n",
      "\n",
      "avg / total       0.87      0.87      0.87       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_y = [lvq2.predict(instance) for instance in x_test]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(y_test, predicted_y, target_names=['0', '1', '2', '3', '4', '5', '6']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvq3 = LVQ.LVQ(x=x_train, y=y_train, n_classes=7, n_neurons=90, epsilon=0.9, p_vectors=[], epsilon_dec_factor=0.001)\n",
    "\n",
    "neurons = lvq3.train_LVQ2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.61      0.64       119\n",
      "          1       1.00      1.00      1.00       124\n",
      "          2       0.99      0.96      0.98       129\n",
      "          3       0.66      0.75      0.70       130\n",
      "          4       0.99      1.00      1.00       124\n",
      "          5       0.90      0.78      0.83       107\n",
      "          6       0.84      0.94      0.89       107\n",
      "\n",
      "avg / total       0.87      0.86      0.86       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_y = [lvq3.predict(instance) for instance in x_test]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(y_test, predicted_y, target_names=['0', '1', '2', '3', '4', '5', '6']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thuật toán LVQ được thêm vào các hàm tính win_map và tỉ lệ các mẫu trong từng neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping1 = lvq1.win_map_LVQ(x_train)\n",
    "mapping2 = lvq2.win_map_LVQ(x_train)\n",
    "mapping3 = lvq3.win_map_LVQ(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "propa1 = lvq1.propabilityLVQ()\n",
    "propa2 = lvq2.propabilityLVQ()\n",
    "propa3 = lvq3.propabilityLVQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array([])\n",
    "\n",
    "for sample in x_test:\n",
    "    pos1 = lvq1.find_closest(sample)\n",
    "    pos2 = lvq2.find_closest(sample)\n",
    "    pos3 = lvq3.find_closest(sample)\n",
    "    l1 = len(mapping1[pos1[0]])\n",
    "    l2 = len(mapping2[pos2[0]])\n",
    "    l3 = len(mapping3[pos3[0]])\n",
    "    pro1 = (l1*propa1[0, pos1[0]] + l2*propa2[0, pos2[0]] + l3*propa3[0, pos3[0]])/(l1+l2+l3)\n",
    "    pro2 = (l1*propa1[1, pos1[0]] + l2*propa2[1, pos2[0]] + l3*propa3[1, pos3[0]])/(l1+l2+l3)\n",
    "    pro3 = (l1*propa1[2, pos1[0]] + l2*propa2[2, pos2[0]] + l3*propa3[2, pos3[0]])/(l1+l2+l3)\n",
    "    pro4 = (l1*propa1[3, pos1[0]] + l2*propa2[3, pos2[0]] + l3*propa3[3, pos3[0]])/(l1+l2+l3)\n",
    "    pro5 = (l1*propa1[4, pos1[0]] + l2*propa2[4, pos2[0]] + l3*propa3[4, pos3[0]])/(l1+l2+l3)\n",
    "    pro6 = (l1*propa1[5, pos1[0]] + l2*propa2[5, pos2[0]] + l3*propa3[5, pos3[0]])/(l1+l2+l3)\n",
    "    pro7 = (l1*propa1[6, pos1[0]] + l2*propa2[6, pos2[0]] + l3*propa3[6, pos3[0]])/(l1+l2+l3)\n",
    "    tmp = np.argmax(np.array([pro1, pro2, pro3, pro4, pro5, pro6, pro7]))\n",
    "    result = np.append(result, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.67      0.70       119\n",
      "          1       0.99      1.00      1.00       124\n",
      "          2       0.98      0.98      0.98       129\n",
      "          3       0.72      0.76      0.74       130\n",
      "          4       0.98      1.00      0.99       124\n",
      "          5       0.90      0.81      0.85       107\n",
      "          6       0.89      0.95      0.92       107\n",
      "\n",
      "avg / total       0.88      0.88      0.88       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, result, target_names=['0', '1', '2', '3', '4', '5', '6']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
